import {SidebarLink} from '@/components/Sidebar.js'
import {SectionAiWeirdness} from '@/app/sections.js'

## AI Role Play

These tendencies are an emergent property of LLMs as technical systems, which may stem from their architecture (hallucinations are intrinsic to GPT models), training data (waluigi-ness emerges from protagonist-antagonist tropes), or training processes (sycophancy is exacerbated by fine-tuning, particularly when it includes human feedback). As models output text often  rendered in a chat interface similar to those used for human to human communication, these tendencies can feel like personality traits, leading to anthropomorphism when thinking about or discussing them.

An alternative way to understand these tendencies, as well as the wider behaviour of LLMs, is through the lens of role play. The 2023 paper ‘Role play with large language models’ describes dialogue agents’ behaviour like so:

> *The underlying LLM’s task, given the dialogue prompt followed by a piece of user-supplied text, is to generate a continuation that conforms to the distribution of the training data … In other words, the dialogue agent will do its best to role-play the character of a dialogue agent as portrayed in the dialogue prompt*
> 

They further discuss how commercially released LLM systems tend to be developed with personas that are friendly or helpful - with observed tendencies to act inversely (Waluigi Effect), or be sycophantic. Role playing therefore becomes a useful frame for presenting and critiquing the effects of LLMs and a key part of *The Models.* We focus particularly on the improvisatory part of role playing exploring the space between base LLMs as text production systems with particular machinic logics and characteristics and the versions fine-tuned to play the role of helpful assistant. 

We take this helpful assistant and ask it to play the role of an (imperfect) actor. The decisions made in the development of the script generation process focus on maintaining and even encouraging the emerging mistakes and slip ups, and in this we were primarily guided by what is surprising and unexpected.